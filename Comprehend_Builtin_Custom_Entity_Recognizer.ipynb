{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GunduSriBhanu/Computer-vision-on-pdf/blob/main/Comprehend_Builtin_Custom_Entity_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "oILU_tgWbWFl"
      },
      "source": [
        "# Amazon Custom Entity Recognizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-rzzg52gbWFm"
      },
      "source": [
        "***Welcome to an end-to-end example of how to use [Amazon Comprehend Custom Entity Recognizer](https://docs.aws.amazon.com/comprehend/latest/dg/custom-entity-recognition.html) to create a custom entity recognition model***\n",
        "\n",
        "Custom entity recognition extends the capability of Amazon Comprehend by helping you identify your specific new entity types that are not in the preset generic entity types. This means that you can analyze documents and extract entities like product codes or business-specific entities that fit your particular needs.\n",
        "\n",
        "Building an accurate custom entity recognizer on your own can be a complex process, requiring preparation of large sets of manually annotated training documents and the selection of the right algorithms and parameters for model training. Amazon Comprehend helps to reduce the complexity by providing automatic annotation and model development to create a custom entity recognition model.\n",
        "\n",
        "Creating a custom entity recognition model is a more effective approach than using string matching or regular expressions to extract entities from documents. For example, to extract ENGINEER names in a document, it is difficult to enumerate all possible names. Additionally, without context, it is challenging to distinguish between ENGINEER names and ANALYST names. A custom entity recognition model can learn the context where those names are likely to appear. Additionally, string matching will not detect entities that have typos or follow new naming conventions, while this is possible using a custom model.\n",
        "\n",
        "In this notebook, we demonstrate how to use [Custom Entity Recognition API](https://docs.aws.amazon.com/comprehend/latest/dg/training-recognizers.html) to create an entity recognition model. The example takes the training dataset in CSV format and runs inference against text input. Comprehend also supports advanced use case that takes Ground Truth annotated data for training and allows you to directly run inference on PDF and Word document. For more information refer to [Custom Entity Recognizer for PDF document](https://aws.amazon.com/blogs/machine-learning/build-a-custom-entity-recognizer-for-pdf-documents-using-amazon-comprehend/).\n",
        "\n",
        "This notebook requires no ML expertise to train a model with the example dataset or with your own business specific dataset. You can use the API operations discussed in this notebook in your own applications.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TNSR4NdwbWFm"
      },
      "source": [
        "## Outline\n",
        "\n",
        "1. [Prerequisites and Set up](#step1)\n",
        "    1. [Install dependencies](#step1.1)\n",
        "    2. [Set up IAM permissions](#step1.2)\n",
        "2. [Dataset Set Up](#step2)\n",
        "    1. [Download the dataset and upload to S3](#step2.1)\n",
        "3. [Train the model](#step3)\n",
        "    1. [Start Training](#step3.1)\n",
        "    2. [Monitor the status of the training job](#step3.2)\n",
        "    3. [Retrieve the trained model metrics](#step3.3)\n",
        "4. [Start a batch entity recognition job](#step4)\n",
        "    1. [Start the batch inference job](#step4.1)\n",
        "    2. [Monitor the batch inference job status ](#step4.2)\n",
        "    3. [Download the output of the batch job](#step4.3)\n",
        "5. [Real-time analysis for custom entity recognition](#step5)\n",
        "    1. [Create Model End Point](#step5.1)\n",
        "    2. [Monitor creation status of the entity recognizer endpoint](#step5.2)\n",
        "    3. [Running real-time custom entity detection](#step5.3)\n",
        "    4. [Stop the End point](#step5.4)\n",
        "6. [Conclusion](#step6)\n",
        "7. [Learn more about Comprehend Custom Entity Recognition](#step7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nO_rfEKCbWFm"
      },
      "source": [
        "## 1. Prerequisites and setup  <a id=\"step1\"></a>\n",
        "***\n",
        "Amazon Compehend Custom Recognizer requires certain access policies that are attached to the IAM role and the Amazon S3 bucket that stores the datasets. By default, these policies are not present in your Amazon SageMaker Studio environment. We show how to set these permissions,  install dependencies, and set up relevant environment variables.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NSEEWCBdbWFn"
      },
      "source": [
        "### 1.1. Install dependencies  <a id=\"step1.1\"></a>\n",
        "\n",
        "Here we install dependencies needed to run the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2BZYxTPSbWFn",
        "outputId": "736034f5-364c-4125-9fbf-8d17520d20b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: botocore in /opt/conda/lib/python3.7/site-packages (1.31.63)\n",
            "Collecting botocore\n",
            "  Obtaining dependency information for botocore from https://files.pythonhosted.org/packages/02/55/7070f28d963cf8843e1335c8c3de0a37dd6382b53e83315ddaab1f645f5e/botocore-1.32.5-py3-none-any.whl.metadata\n",
            "  Downloading botocore-1.32.5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from botocore)\n",
            "  Obtaining dependency information for urllib3<1.27,>=1.25.4 from https://files.pythonhosted.org/packages/b0/53/aa91e163dcfd1e5b82d8a890ecf13314e3e149c05270cc644581f77f17fd/urllib3-1.26.18-py2.py3-none-any.whl.metadata\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m859.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.14.0)\n",
            "Downloading botocore-1.32.5-py3-none-any.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: urllib3, botocore\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.6\n",
            "    Uninstalling urllib3-2.0.6:\n",
            "      Successfully uninstalled urllib3-2.0.6\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.31.63\n",
            "    Uninstalling botocore-1.31.63:\n",
            "      Successfully uninstalled botocore-1.31.63\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.32.5 which is incompatible.\n",
            "awscli 1.29.63 requires botocore==1.31.63, but you have botocore 1.32.5 which is incompatible.\n",
            "awscli 1.29.63 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\n",
            "boto3 1.28.63 requires botocore<1.32.0,>=1.31.63, but you have botocore 1.32.5 which is incompatible.\n",
            "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed botocore-1.32.5 urllib3-1.26.18\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (1.28.63)\n",
            "Collecting boto3\n",
            "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/f2/23/c5545cb57abfc3a9782287f2845a26286f6f9f7bcec36f13569567f950fe/boto3-1.29.5-py3-none-any.whl.metadata\n",
            "  Downloading boto3-1.29.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: botocore<1.33.0,>=1.32.5 in /opt/conda/lib/python3.7/site-packages (from boto3) (1.32.5)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from boto3) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.33.0,>=1.32.5->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.33.0,>=1.32.5->boto3) (1.26.18)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.33.0,>=1.32.5->boto3) (1.14.0)\n",
            "Downloading boto3-1.29.5-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: boto3\n",
            "  Attempting uninstall: boto3\n",
            "    Found existing installation: boto3 1.28.63\n",
            "    Uninstalling boto3-1.28.63:\n",
            "      Successfully uninstalled boto3-1.28.63\n",
            "Successfully installed boto3-1.29.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "CPU times: user 306 ms, sys: 44.2 ms, total: 350 ms\n",
            "Wall time: 13.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "## Upgrade boto3 and botocore\n",
        "!pip install botocore --upgrade\n",
        "!pip install boto3 --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ecOFaghUbWFn"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import boto3\n",
        "import json\n",
        "import sagemaker as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "QNHpT5x8bWFn"
      },
      "source": [
        "Initialize service object and set up variables to keep the value of the current AWS account id, region, role, and the default SageMaker S3 bucket name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8n6zHOOQbWFo",
        "outputId": "0c44d3b6-3112-4db1-dfb1-e0ce75bb962a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
            "  warnings.warn(warning, PythonDeprecationWarning)\n"
          ]
        }
      ],
      "source": [
        "sts_client = boto3.client(\"sts\")\n",
        "s3 = boto3.resource('s3')\n",
        "s3_client = boto3.client('s3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RkudPOPabWFo",
        "outputId": "d181c282-85ad-4a8d-f7d4-b292dc8ae102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your account id is 054719795948\n",
            "Your current region is us-west-2\n",
            "Your current role is AmazonSageMaker-ExecutionRole-20231003T093231\n",
            "Bucket name used is sagemaker-us-west-2-054719795948\n"
          ]
        }
      ],
      "source": [
        "# Get current AWS Account ID\n",
        "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
        "print(\"Your account id is {}\".format(account_id))\n",
        "\n",
        "# Get currrent region\n",
        "session = boto3.session.Session()\n",
        "region = session.region_name\n",
        "print(\"Your current region is {}\".format(region))\n",
        "\n",
        "# Get current role\n",
        "role_arn = sm.get_execution_role()\n",
        "role_name = role_arn.split('/')[len(role_arn.split('/'))-1]\n",
        "print(\"Your current role is {}\".format(role_name))\n",
        "\n",
        "# Get SageMaker default S3 Bucket\n",
        "bucket_name = sm.Session().default_bucket()\n",
        "print (\"Bucket name used is \" + bucket_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IAEJs7aDbWFo"
      },
      "source": [
        "### 1.2. Set up IAM permissions  <a id=\"step1.2\"></a>\n",
        "***\n",
        "To use the Amazon Comprehend Custom Entity Recognition APIs in Sagemaker Studio, we need to attach <b>ComprehendFullAccess</b> and <b>AmazonS3FullAccess</b> policies to the IAM role associated with the Sagemaker Studio user. These policies provides full access to Amazon Comprehend Custom Entity Recognition and to Amazon S3.\n",
        "\n",
        "The policies cannot be attached to the current IAM role from inside the notebook. You can attach the policies by using the IAM console or by using AWS CloudShell. We show how to attach the policies by using CloudShell.\n",
        "\n",
        "**Note:** For a production application, we recommend that you restrict access policies to only those needed to run the application. Permissions can be restricted based on the use case (training/inference) and specific resource names (such as a full S3 bucket name or an S3 bucket name pattern). You should also restrict access to the Custom Entity Recognition or Amazon Sagemaker operations to just those that your application needs.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IA7f3Og4bWFo",
        "outputId": "ab8bb471-d6d5-4efc-ade7-eb4c1a4894e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;39;43mPlease copy the following command and execute in CloudShell:\u001b[0m\n",
            "aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/ComprehendFullAccess --role-name AmazonSageMaker-ExecutionRole-20231003T093231  && aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --role-name AmazonSageMaker-ExecutionRole-20231003T093231 && aws iam update-assume-role-policy --policy-document '{\"Version\": \"2012-10-17\", \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"sagemaker.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}, {\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"comprehend.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]}' --role-name AmazonSageMaker-ExecutionRole-20231003T093231 && aws iam put-role-policy --policy-name ComprehendLabAssumeRole --policy-document '{\"Version\": \"2012-10-17\", \"Statement\": [{\"Effect\": \"Allow\", \"Action\": [\"iam:PassRole\"], \"Resource\": \"*\"}]}'  --role-name AmazonSageMaker-ExecutionRole-20231003T093231\n"
          ]
        }
      ],
      "source": [
        "# Command to attach AmazonComprehendFullAccess to the IAM role.\n",
        "cmd_1 = f\"aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/ComprehendFullAccess --role-name {role_name} \"\n",
        "\n",
        "# Command to attach AmazonS3FullAccess to the IAM role.\n",
        "cmd_2 = f\"aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --role-name {role_name}\"\n",
        "\n",
        "# Command to assume Comprehend role to the SageMaker role.\n",
        "trust_relationship_policy_comprehend = {\n",
        "    \"Version\": \"2012-10-17\",\n",
        "    \"Statement\": [\n",
        "        {\n",
        "            \"Effect\": \"Allow\",\n",
        "            \"Principal\": {\n",
        "                \"Service\": \"sagemaker.amazonaws.com\"\n",
        "            },\n",
        "            \"Action\": \"sts:AssumeRole\"\n",
        "        },\n",
        "        {\n",
        "            \"Effect\": \"Allow\",\n",
        "            \"Principal\": {\n",
        "                \"Service\": \"comprehend.amazonaws.com\"\n",
        "            },\n",
        "            \"Action\": \"sts:AssumeRole\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "cmd_3 = f\"aws iam update-assume-role-policy --policy-document '{json.dumps(trust_relationship_policy_comprehend)}' --role-name {role_name}\"\n",
        "\n",
        "iam_pass = {\n",
        "    \"Version\": \"2012-10-17\",\n",
        "    \"Statement\": [\n",
        "        {\n",
        "            \"Effect\": \"Allow\",\n",
        "            \"Action\": [\n",
        "                \"iam:PassRole\"\n",
        "            ],\n",
        "            \"Resource\": \"*\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "cmd_4 = f\"aws iam put-role-policy --policy-name ComprehendLabAssumeRole --policy-document '{json.dumps(iam_pass)}'  --role-name {role_name}\"\n",
        "\n",
        "# Next, we print the commands which attach the required role.\n",
        "print(\"\\x1b[0;39;43m\" + \"Please copy the following command and execute in CloudShell:\" + \"\\x1b[0m\")\n",
        "print(f\"{cmd_1} && {cmd_2} && {cmd_3} && {cmd_4}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "nlgW6ZJdbWFo"
      },
      "source": [
        "### **Attach IAM policies by using AWS CloudShell**\n",
        "\n",
        "***\n",
        "You can attach the required policies by running a command from any shell authenticated with the credentials of the current AWS account. For simplicity, we use the AWS CloudShell service.\n",
        "\n",
        "**To attach the IAM policies**\n",
        "\n",
        "1. Open the [CloudShell console](https://aws.amazon.com/cloudshell/) in the same AWS account as the current Sagemaker Studio domain. It might take up to a minute to start. Note that the IAM role used in Cloudshell must be able to change IAM permissions. Typically, the Administrator role can change IAM permissions.\n",
        "\n",
        "![cloudshell_part_1.png](https://jumpstart-cache-prod-us-west-2.s3.us-west-2.amazonaws.com/ai_services_assets/custom_labels/screenshots/cloudshell_screenshot_part_1.png)\n",
        "\n",
        "2. At the CloudShell command prompt, run the command that you noted in the output from the previous cell.\n",
        "\n",
        "![cloudshell_part_2.jpeg](https://jumpstart-cache-prod-us-west-2.s3.us-west-2.amazonaws.com/ai_services_assets/custom_labels/screenshots/cloudshell_screenshot_part_2.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JWvF-EKCbWFp"
      },
      "source": [
        "## 2. Set up the example datasets  <a id=\"step2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "jO4CQyRWbWFp"
      },
      "source": [
        "### 2.1 Download the dataset and upload to S3.   <a id=\"step2.1\"></a>\n",
        "The dataset we will use for this example is AWS Product Announcement messages from a public demo website. The dataset contains more than 3000 entries collected from AWS product announcements. In this case, we will download the dataset since it's small.\n",
        "\n",
        "The demo website contains the following files. The training and testing dataset includes the original AWS announcement messages. The Entity List training file contains 2 columns with mapping between the entity value in the original message and the entity label name we want Comprehend Custom Recognizer to detect.\n",
        "\n",
        "1. Training Dataset - aws-offering-docs.txt\n",
        "2. Test Dataset - aws-offerings-test.txt\n",
        "3. Entity List training dataset - aws-offerings.csv\n",
        "\n",
        "We will use the training dataset to train a Comprehend Entity Recognization model to detect the below entity:\n",
        "* AWS_OFFERING\n",
        "\n",
        "The code below will download the files to your SageMaker Studio and upload them to the S3 bucket we created earlier, so it is ready for the Comprehend Custom Recogizer training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n4CCnHTxbWFp"
      },
      "outputs": [],
      "source": [
        "s3_client = boto3.client('s3')\n",
        "s3_entity_prefix = 'entity-training'\n",
        "\n",
        "training_data_bucket = f\"jumpstart-cache-prod-{region}\"\n",
        "training_data_prefix = \"training-datasets/comprehend\"\n",
        "\n",
        "s3_client.download_file(training_data_bucket, f\"{training_data_prefix}/aws-offerings.csv\", \"aws-offerings.csv\")\n",
        "response = s3_client.upload_file('./aws-offerings.csv', bucket_name, \"comprehend_lab/{}/aws-offerings.csv\".format(s3_entity_prefix))\n",
        "\n",
        "s3_client.download_file(training_data_bucket, f\"{training_data_prefix}/aws-offerings-docs.txt\", \"aws-offerings-docs.txt\")\n",
        "response = s3_client.upload_file('./aws-offerings-docs.txt', bucket_name, \"comprehend_lab/{}/aws-offerings-docs.txt\".format(s3_entity_prefix))\n",
        "\n",
        "s3_client.download_file(training_data_bucket, f\"{training_data_prefix}/aws-offerings-test.txt\", \"aws-offerings-test.txt\")\n",
        "response = s3_client.upload_file('./aws-offerings-test.txt', bucket_name, \"comprehend_lab/{}/aws-offerings-test.txt\".format(s3_entity_prefix))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tur3KCosbWFp"
      },
      "source": [
        "Let's take a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QMOJ_ZYobWFp",
        "outputId": "3c420794-f9c0-4896-c388-3b3669709681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Text\", \"Type\"\n",
            "\"ACM\", \"AWS_OFFERING\"\n",
            "\"ACM PCA\", \"AWS_OFFERING\"\n",
            "\"ACM Private CA\", \"AWS_OFFERING\"\n",
            "\"AD Connector\", \"AWS_OFFERING\"\n",
            "\"AMS\", \"AWS_OFFERING\"\n",
            "\"API Gateway\", \"AWS_OFFERING\"\n",
            "\"AWS\", \"AWS_OFFERING\"\n",
            "\"AWS Amplify\", \"AWS_OFFERING\"\n",
            "\"AWS App Mesh\", \"AWS_OFFERING\"\n",
            "\"AWS AppSync\", \"AWS_OFFERING\"\n",
            "\"AWS Application Auto Scaling\", \"AWS_OFFERING\"\n",
            "\"AWS Application Discovery Service\", \"AWS_OFFERING\"\n",
            "\"AWS Artifact\", \"AWS_OFFERING\"\n",
            "\"AWS Auto Scaling\", \"AWS_OFFERING\"\n",
            "\"AWS Backup\", \"AWS_OFFERING\"\n",
            "\"AWS Batch\", \"AWS_OFFERING\"\n",
            "\"AWS Billing and Cost Management\", \"AWS_OFFERING\"\n",
            "\"AWS Blockchain Templates\", \"AWS_OFFERING\"\n",
            "\"AWS CLI\", \"AWS_OFFERING\"\n"
          ]
        }
      ],
      "source": [
        "!head -20 aws-offerings.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yylKtb_bbWFp",
        "outputId": "aad5f7b9-298e-45e4-ad94-9b2a3396a57f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AWS X-Ray Supports Analytics\n",
            "Use Analytics in X-Ray and delve into traces to quickly pinpoint issues that may effect your application and its underlying services.\n",
            "Amazon Sumerian Service Update on 2019-04-26\n",
            "Service improvements for Amazon Sumerian.\n",
            "Release: Amazon GameLift on 2019-04-25\n",
            "Realtime Servers provides ready-to-go, customizable game servers for mobile multiplayer games.\n",
            "AWS Budgets now Supports Instance Family Filtering for Reservation Coverage Alerts\n",
            "Starting today, you can use AWS Budgets to create Reservation Coverage budgets to monitor your Amazon EC2 reservations for a given instance family, and receive alerts when your reservation coverage falls below the threshold you define.\n",
            "Amazon Sumerian Service Update on 2019-04-08\n",
            "Service improvements for Amazon Sumerian.\n",
            "AWS X-Ray Supports AWS App Mesh Integration\n",
            "Use X-Ray to trace communications through AWS App Mesh's service mesh as it networks across multiple types of computer infrastructure.\n",
            "AWS X-Ray Groups: Deep Dive Dev Blog\n",
            "Use groups in X-Ray to create filtered service maps and record metrics for requests to a microservice, from a specific user, or for a recurring error case.\n",
            "AWS Announces the Ability to Consolidate Your Daily Credit Memos and Tax Credit Note Documents\n",
            "Amazon Web Services (AWS) is pleased to announce that you now have the option to have refunds and credits consolidated into a single credit memo instead of receiving multiple credit memos on the same day.\n",
            "AWS Deep Learning Containers for MXNet\n",
            "The AWS Deep Learning Containers for MXNet include containers for Training and Inference for CPU and GPU, optimized for performance and scale on AWS.\n",
            "AWS Deep Learning Containers for TensorFlow\n",
            "The AWS Deep Learning Containers for TensorFlow include containers for Training and Inference for CPU and GPU, optimized for performance and scale on AWS.\n"
          ]
        }
      ],
      "source": [
        "!head -20 aws-offerings-docs.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-wi_wk2dbWFp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Qrh-rMYxbWFp"
      },
      "source": [
        "## 3. Train the model  <a id=\"step3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xx11m-JebWFp"
      },
      "source": [
        "### 3.1 Start training job  <a id=\"step3.1\"></a>\n",
        "Automatically train the recognizer to label words or sets of adjacent words with custom entity types. Automatic training requires having two types of information: sample documents and the entity list or annotations. Once the recognizer is trained, you can use it to detect custom entities in your documents. You can quickly analyze a small body of text in real time, or you can analyze a large set of documents with an asynchronous job.\n",
        "\n",
        "You can prepare separate training and testing datasets for Comprehend custom entity recognizer training and model evaluation. Or only provide one dataset for both training and testing. Comprehend will automatically select 10% of your provided dataset to use as testing data. In the below example, we specified the training dataset as *Documents.S3Uri* under *InputDataConfig*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SmcAN7ztbWFp",
        "outputId": "48472b08-16bf-49cb-e62f-1648ba6aa721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ARN for the entity recognizer is arn:aws:comprehend:us-west-2:054719795948:entity-recognizer/jumpstart-cer-2f06259c-56b1-49f1-92b0-3c663ebb43df\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "\n",
        "comprehend_client = boto3.client(\"comprehend\")\n",
        "\n",
        "custom_recognizer_name = f'jumpstart-cer-{uuid.uuid4()}'\n",
        "\n",
        "response = comprehend_client.create_entity_recognizer(\n",
        "    RecognizerName=custom_recognizer_name,\n",
        "    LanguageCode=\"en\",\n",
        "    DataAccessRoleArn=role_arn,\n",
        "    InputDataConfig={\n",
        "        \"EntityTypes\": [\n",
        "            {\n",
        "                'Type': \"AWS_OFFERING\"\n",
        "            }\n",
        "        ],\n",
        "        'EntityList': {\n",
        "            'S3Uri': \"s3://{}/comprehend_lab/{}/aws-offerings.csv\".format(bucket_name,s3_entity_prefix)\n",
        "        },\n",
        "        'Documents': {\n",
        "            'S3Uri': \"s3://{}/comprehend_lab/{}/aws-offerings-docs.txt\".format(bucket_name,s3_entity_prefix)\n",
        "        },\n",
        "\n",
        "    }\n",
        ")\n",
        "recognizer_arn = response[\"EntityRecognizerArn\"]\n",
        "print(\"The ARN for the entity recognizer is {}\".format(recognizer_arn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uiBV_fA8bWFp"
      },
      "source": [
        "### 3.2 Monitor the status of the training job  <a id=\"step3.2\"></a>\n",
        "The below code will monitor the training job status and stop when the model is ready. The process may take around 15 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1G3eHDOXbWFp",
        "outputId": "51f7cb47-f289-48ec-8ea9-df26b9ee0402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18:51:39 : Custom document entity recognizer: TRAINED\n",
            "CPU times: user 1.28 s, sys: 109 ms, total: 1.39 s\n",
            "Wall time: 14min 6s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Loop through and wait for the training to complete . Takes up to 10 mins\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "max_time = time.time() + 3*60*60 # 3 hours\n",
        "while time.time() < max_time:\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%H:%M:%S\")\n",
        "    describe_custom_recognizer = comprehend_client.describe_entity_recognizer(\n",
        "        EntityRecognizerArn=recognizer_arn\n",
        "    )\n",
        "    status = describe_custom_recognizer[\"EntityRecognizerProperties\"][\"Status\"]\n",
        "    clear_output(wait=True)\n",
        "    print(f\"{current_time} : Custom document entity recognizer: {status}\")\n",
        "\n",
        "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
        "        break\n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FswpG6gTbWFq"
      },
      "source": [
        "### 3.3 Retrieve the trained model metrics  <a id=\"step3.3\"></a>\n",
        "\n",
        "Amazon Comprehend provides you with metrics to help you estimate how well an entity recognizer should work for your job. They are based on training the recognizer model, and so while they accurately represent the performance of the model during training, they are only an approximation of the API performance during entity discovery.\n",
        "\n",
        "Metrics are returned any time metadata from a trained entity recognizer is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_BGFQapcbWFq",
        "outputId": "df87cb81-02c7-4551-b6b8-3b44145e24a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Precision': 96.57142857142857,\n",
              " 'Recall': 97.40634005763688,\n",
              " 'F1Score': 96.98708751793401}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "describe_custom_recognizer['EntityRecognizerProperties']['RecognizerMetadata']['EvaluationMetrics']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vwX6We1jbWFq"
      },
      "source": [
        "## 4. Start a batch entity recognition job  <a id=\"step4\"></a>\n",
        "You can run an asynchronous analysis job to detect custom entities in a set of one or more documents. We will use the testing dataset in the below step to run a batch job against the newly trained Custom Recognizer model.\n",
        "### 4.1 Start the batch inference job  <a id=\"step4.1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_9oML5FZbWFq"
      },
      "outputs": [],
      "source": [
        "response = comprehend_client.start_entities_detection_job(\n",
        "    JobName='AWS_OFFERING-001',\n",
        "    EntityRecognizerArn=recognizer_arn,\n",
        "    LanguageCode=\"en\",\n",
        "    DataAccessRoleArn=role_arn,\n",
        "    InputDataConfig={\n",
        "        'S3Uri': \"s3://{}/comprehend_lab/{}/aws-offerings-test.txt\".format(bucket_name,s3_entity_prefix),\n",
        "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
        "    },\n",
        "    OutputDataConfig={\n",
        "        'S3Uri': \"s3://{}/comprehend_lab/{}/results/\".format(bucket_name,s3_entity_prefix)\n",
        "    }\n",
        ")\n",
        "job_id = response['JobId']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OkliiinebWFq"
      },
      "source": [
        "Amazon Comprehend batch job responds with the JobID and JobStatus and will return the output from the job in the S3 bucket that you specified in your request.\n",
        "### 4.2 Monitor the batch inference job status  <a id=\"step4.2\"></a>\n",
        "We can use the JobID to get the status of the batch job.\n",
        "\n",
        "The below code will monitor the batch job status and stop when it is done. The process may take around 20 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VPzjqHsfbWFq",
        "outputId": "7a2678e1-d7bf-4a18-a157-e7aee032e63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18:57:54 : Custom document entity batch job: COMPLETED\n"
          ]
        }
      ],
      "source": [
        "max_time = time.time() + 3*60*60 # 3 hours\n",
        "while time.time() < max_time:\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%H:%M:%S\")\n",
        "    response = comprehend_client.describe_entities_detection_job(\n",
        "        JobId=job_id\n",
        "    )\n",
        "    status = response[\"EntitiesDetectionJobProperties\"][\"JobStatus\"]\n",
        "    clear_output(wait=True)\n",
        "    print(f\"{current_time} : Custom document entity batch job: {status}\")\n",
        "\n",
        "    if status == \"COMPLETED\" or status == \"FAILED\":\n",
        "        break\n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "u3nVh-bHbWFq"
      },
      "source": [
        "### 4.3  Download the output of the batch job  <a id=\"step4.3\"></a>\n",
        "Now the batch job is completed. Let's download the output from the S3 bucket and take a closer look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ugUFeNcKbWFq",
        "outputId": "182c6558-cbdb-4c17-c344-57bcc693c18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
            "output\n"
          ]
        }
      ],
      "source": [
        "response = comprehend_client.describe_entities_detection_job(\n",
        "    JobId=job_id\n",
        ")\n",
        "if response['EntitiesDetectionJobProperties']['JobStatus'] == \"COMPLETED\":\n",
        "    output_s3_uri = response['EntitiesDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
        "    s3_key = output_s3_uri.replace(\"s3://{}/\".format(bucket_name),'')\n",
        "    s3.meta.client.download_file(bucket_name, s3_key, 'output.tar.gz')\n",
        "    !tar zxvf output.tar.gz\n",
        "else:\n",
        "    print(\"Batch transformation job not complete.  Please wait until this job is completed before attempting to view output.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "sxwlnYFpbWFq"
      },
      "source": [
        "Let's review the test data and the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9JL4Yup2bWFq",
        "outputId": "41b3ea99-7c6b-4333-9e59-a64492dd7717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Great connecting with other #AWS ninjas today at #AWSSummitLondon 🐱‍👤 @awscloud\n",
            "\"How far out is Fargate?\" - Diving into the strengths and weaknesses of #AWS #Fargate with Michael Lavers.\n",
            "AWS announces availability of Amazon Managed Blockchain service http://bit.ly/2H3oepU\n",
            "New in #AWS: Amazon Kinesis Data Analytics now allows you to assign AWS resource tags to your real-time applications\n",
            "Serverless has become the most used deployment pattern for cloud applications. In this field, AWS Lambda is a very well known player. Every developer wants to get his hands dirty with lambda, build a quick function code, and run it. \n",
            "At re:Invent 2050, Amazon announced a new product called Amazon DeepThought.  It is the most amazing cloud service ever developed."
          ]
        }
      ],
      "source": [
        "!head -20 aws-offerings-test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-vJd7zPPbWFq",
        "outputId": "a4926c1c-c9b5-4809-cc33-fd921453514d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"Entities\": [], \"File\": \"aws-offerings-test.txt\", \"Line\": 0}\n",
            "{\"Entities\": [], \"File\": \"aws-offerings-test.txt\", \"Line\": 1}\n",
            "{\"Entities\": [{\"BeginOffset\": 0, \"EndOffset\": 3, \"Score\": 1.0, \"Text\": \"AWS\", \"Type\": \"AWS_OFFERING\"}, {\"BeginOffset\": 30, \"EndOffset\": 55, \"Score\": 1.0, \"Text\": \"Amazon Managed Blockchain\", \"Type\": \"AWS_OFFERING\"}], \"File\": \"aws-offerings-test.txt\", \"Line\": 2}\n",
            "{\"Entities\": [{\"BeginOffset\": 13, \"EndOffset\": 42, \"Score\": 0.9130047913060774, \"Text\": \"Amazon Kinesis Data Analytics\", \"Type\": \"AWS_OFFERING\"}, {\"BeginOffset\": 68, \"EndOffset\": 71, \"Score\": 1.0, \"Text\": \"AWS\", \"Type\": \"AWS_OFFERING\"}], \"File\": \"aws-offerings-test.txt\", \"Line\": 3}\n",
            "{\"Entities\": [{\"BeginOffset\": 94, \"EndOffset\": 104, \"Score\": 0.9999999403953606, \"Text\": \"AWS Lambda\", \"Type\": \"AWS_OFFERING\"}], \"File\": \"aws-offerings-test.txt\", \"Line\": 4}\n",
            "{\"Entities\": [{\"BeginOffset\": 57, \"EndOffset\": 75, \"Score\": 0.9997209494040638, \"Text\": \"Amazon DeepThought\", \"Type\": \"AWS_OFFERING\"}], \"File\": \"aws-offerings-test.txt\", \"Line\": 5}\n"
          ]
        }
      ],
      "source": [
        "!cat output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "jILfJIxDbWFq"
      },
      "source": [
        "## 5. Real-time analysis for custom entity recognition  <a id=\"step5\"></a>\n",
        "With Amazon Comprehend, you can quickly detect custom entities in individual text documents by running real-time analysis. Unlike asynchronous batch jobs that analyze large documents or large sets of documents, real-time analysis is useful for applications that process small bodies of text as they arrive. For example, you can immediately detect custom entities in social media posts, support tickets, or customer reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mdnKuWWCbWFq"
      },
      "source": [
        "### 5.1 Create Model End Point  <a id=\"step5.1\"></a>\n",
        "You create an endpoint to make your custom model available for real-time analysis.\n",
        "\n",
        "To meet your text processing needs, you assign inference units to the endpoint, and each unit allows a throughput of 100 characters per second for up to 2 documents per second. You can then adjust the throughput up or down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4XFRr0qqbWFq",
        "outputId": "28f674bd-9e92-4639-af0a-9524ab741c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document Entity Recognition Endpoint ARN: arn:aws:comprehend:us-west-2:054719795948:entity-recognizer-endpoint/jumpstart-demo-custom-ner-endpoint\n"
          ]
        }
      ],
      "source": [
        "realtime_endpoint_name = f'jumpstart-demo-custom-ner-endpoint'\n",
        "endpoint_arn = ''\n",
        "\n",
        "try:\n",
        "    response = comprehend_client.create_endpoint(\n",
        "        EndpointName=realtime_endpoint_name,\n",
        "        ModelArn=recognizer_arn,\n",
        "        DesiredInferenceUnits=10\n",
        "    )\n",
        "    endpoint_arn = response['EndpointArn']\n",
        "except Exception as error:\n",
        "    print(error)\n",
        "\n",
        "\n",
        "print('Document Entity Recognition Endpoint ARN: ' + endpoint_arn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "j18lzh18bWFu"
      },
      "source": [
        "### 5.2 Monitor creation status of the entity recognizer endpoint  <a id=\"step5.2\"></a>\n",
        "The below code will monitor the endpoint deployment job status and stop when it is done. The process may take around 10 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fpahLn5JbWFu",
        "outputId": "3ef87c32-884c-438e-ac13-ab9283747d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19:06:50 : Custom entity recognizer Entity Recognition: IN_SERVICE\n",
            "CPU times: user 681 ms, sys: 53.7 ms, total: 734 ms\n",
            "Wall time: 7min 23s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Loop through and wait for the training to complete . Takes up to 10 mins\n",
        "max_time = time.time() + 3*60*60 # 3 hours\n",
        "while time.time() < max_time:\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%H:%M:%S\")\n",
        "\n",
        "    describe_endpoint_resp = comprehend_client.describe_endpoint(\n",
        "        EndpointArn=endpoint_arn\n",
        "    )\n",
        "    status = describe_endpoint_resp[\"EndpointProperties\"][\"Status\"]\n",
        "    clear_output(wait=True)\n",
        "    print(f\"{current_time} : Custom entity recognizer Entity Recognition: {status}\")\n",
        "\n",
        "    if status == \"IN_SERVICE\" or status == \"FAILED\":\n",
        "        break\n",
        "\n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nkWeKRNdbWFu"
      },
      "source": [
        "### 5.3 Running real-time custom entity detection  <a id=\"step5.3\"></a>\n",
        "After you create an endpoint for your custom entity recognizer model, you can run real-time analysis to quickly detect entities in individual bodies of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3RDUa2V8bWFu",
        "outputId": "392e7361-b693-4e2a-bf21-b8d2a6a51f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: Fargate, Score: 0.6265328526496887, Offset: 15-22\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "How far out is <b style=\"color:red\">Fargate</b>? - Diving into the strengths and weaknesses of #AWS #Fargate with Michael Lavers."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Text: AWS, Score: 1.0, Offset: 0-3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<b style=\"color:red\">AWS</b> announces availability of Amazon Managed Blockchain service http://bit.ly/2H3oepU"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Text: Amazon Kinesis Data Analytics, Score: 0.9130048155784607, Offset: 13-42\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "New in #AWS: <b style=\"color:red\">Amazon Kinesis Data Analytics</b> now allows you to assign AWS resource tags to your real-time applications"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Text: AWS Lambda, Score: 0.9999999403953552, Offset: 94-104\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Serverless has become the most used deployment pattern for cloud applications. In this field, <b style=\"color:red\">AWS Lambda</b> is a very well known player. Every developer wants to get his hands dirty with lambda, build a quick function code, and run it."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Text: Amazon DeepThought, Score: 0.9997209310531616, Offset: 57-75\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "At re:Invent 2050, Amazon announced a new product called <b style=\"color:red\">Amazon DeepThought</b>.  It is the most amazing cloud service ever developed."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "examples = [\n",
        "    \"Great connecting with other #AWS ninjas today at #AWSSummitLondon\",\n",
        "    \"How far out is Fargate? - Diving into the strengths and weaknesses of #AWS #Fargate with Michael Lavers.\",\n",
        "    \"AWS announces availability of Amazon Managed Blockchain service http://bit.ly/2H3oepU\",\n",
        "    \"New in #AWS: Amazon Kinesis Data Analytics now allows you to assign AWS resource tags to your real-time applications\",\n",
        "    \"Serverless has become the most used deployment pattern for cloud applications. In this field, AWS Lambda is a very well known player. Every developer wants to get his hands dirty with lambda, build a quick function code, and run it.\",\n",
        "    \"At re:Invent 2050, Amazon announced a new product called Amazon DeepThought.  It is the most amazing cloud service ever developed.\",\n",
        "    \"Michael Lavers approved Stainless steel bulb on 10 ft capillary \",\n",
        "    \"Set at 35degF with adjustable range of 25deg to 325degF \",\n",
        "    \"Electrical rating of 22 amp with voltage from 125 to 480V AC \",\n",
        "    \"NEMA - 4X metal enclosure \"\n",
        "]\n",
        "\n",
        "for i in range(0,len(examples)):\n",
        "    response = comprehend_client.detect_entities(\n",
        "        Text=examples[i],\n",
        "        EndpointArn=endpoint_arn,\n",
        "        LanguageCode=\"en\",\n",
        "    )\n",
        "    # Detect entities\n",
        "    entities =  comprehend.detect_entities(LanguageCode=\"en\", Text=examples[i])\n",
        "\n",
        "    if \"Entities\" in response and len(response[\"Entities\"]) > 0:\n",
        "        entity = response[\"Entities\"][0]\n",
        "        print(f'Text: {entity[\"Text\"]}, Score: {entity[\"Score\"]}, Offset: {entity[\"BeginOffset\"]}-{entity[\"EndOffset\"]}')\n",
        "        display(HTML(examples[i][0:entity[\"BeginOffset\"]] + '<b style=\"color:red\">'+ examples[i][entity[\"BeginOffset\"]:entity[\"EndOffset\"]] +'</b>' + examples[i][entity[\"EndOffset\"]: len(examples[i])]))\n",
        "        print()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QgjSfUbbWFu"
      },
      "source": [
        "### 5.3 Running real-time built in entity detection  <a id=\"step5.3\"></a>\n",
        "By using built in entity recognizer model, you can run real-time analysis to quickly detect entities in individual bodies of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Qvwnb4zUbWFu",
        "outputId": "489dcd78-f099-4ee9-8572-948f5cec676d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built in : PERSON\t=>\tMichael Lavers\n",
            "Built in : QUANTITY\t=>\t10 ft\n",
            "Built in : QUANTITY\t=>\t35degF\n",
            "Built in : QUANTITY\t=>\t25deg\n",
            "Built in : QUANTITY\t=>\t325degF\n",
            "Built in : QUANTITY\t=>\t22 amp\n",
            "Built in : QUANTITY\t=>\t125\n",
            "Built in : QUANTITY\t=>\t480V\n",
            "Built in : ORGANIZATION\t=>\tNEMA\n",
            "Built in : QUANTITY\t=>\t4X\n"
          ]
        }
      ],
      "source": [
        "comprehend = boto3.client('comprehend')\n",
        "# Detect entities\n",
        "for i in range(6,len(examples)):\n",
        "    #print(examples[i])\n",
        "    entities =  comprehend.detect_entities(LanguageCode=\"en\", Text=examples[i])\n",
        "\n",
        "    #print(entities[\"Entities\"])\n",
        "    #print(response[\"Entities\"][\"Text\"], response[\"Entities\"][\"Type\"])\n",
        "    #print(\"\\nEntities\\n========\")\n",
        "\n",
        "    for entity in entities[\"Entities\"]:\n",
        "        print (\"Built in : {}\\t=>\\t{}\".format(entity[\"Type\"], entity[\"Text\"]))\n",
        "\n",
        "\n",
        "#print(\"\\nEntities\\n========\")\n",
        "#for entity in entities[\"Entities\"]:\n",
        "    #print (\"{}\\t=>\\t{}\".format(entity[\"Type\"], entity[\"Text\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "u333BlkibWFu"
      },
      "source": [
        "### 5.4 Stop the End point  <a id=\"step5.4\"></a>\n",
        "The cost for real-time Custom Entity Recognition is based on both the throughput you set and the length of time the endpoint is active.  We clean up the end point here to save cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "V5k7eN7IbWFu",
        "outputId": "b8619cb1-6fd5-4ba9-ad9b-423eda20559a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ResponseMetadata': {'RequestId': '50915118-1101-469f-8dfa-9abbb5f2484d',\n",
              "  'HTTPStatusCode': 200,\n",
              "  'HTTPHeaders': {'x-amzn-requestid': '50915118-1101-469f-8dfa-9abbb5f2484d',\n",
              "   'content-type': 'application/x-amz-json-1.1',\n",
              "   'content-length': '2',\n",
              "   'date': 'Wed, 22 Nov 2023 19:45:36 GMT'},\n",
              "  'RetryAttempts': 0}}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = comprehend_client.delete_endpoint(\n",
        "    EndpointArn = endpoint_arn\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "K-5W1AIqbWFu"
      },
      "source": [
        "## 6. Conclusion  <a id=\"step6\"></a>\n",
        "Creating a custom entity recognition model is a more effective approach than using string matching or regular expressions to extract entities from documents. For example, to extract ENGINEER names in a document, it is difficult to enumerate all possible names. Additionally, without context, it is challenging to distinguish between ENGINEER names and ANALYST names. A custom entity recognition model can learn the context where those names are likely to appear. Additionally, string matching will not detect entities that have typos or follow new naming conventions, while this is possible using a custom model.\n",
        "\n",
        "In this notebook, we showed you how to use the Customr Entity Recognization Model. The notebook showed how to process data to create the training and test datasets, train a model, host a model, run inference, and stop a model.  To do this we provided example datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5PLkJgJgbWFv"
      },
      "source": [
        "### 7. Additional resources  <a id=\"step7\"></a>\n",
        "***\n",
        "\n",
        "To learn more about the Comprehend Custom Entity Recognizer, see [Amazon Comprehend Custom entity recognition](https://docs.aws.amazon.com/comprehend/latest/dg/custom-entity-recognition.html).\n",
        "\n",
        "Post your questions related to Comprehend and find the other FAQs at: https://repost.aws/tags/TArJuWuDW_RS2Qbz1XXvbVzA/amazon-comprehend.\n",
        "\n",
        "***"
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}